Predictive Maintainence for Manufacturing Equipment
==============================

A short description of the project.

Project Organization
------------

    â”œâ”€â”€Pictures             <- Contains app pictures   
    â”œâ”€â”€ artifacts          <- file generated and captured from an experiment's run or job
    â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
    â”œâ”€â”€ data                    <- Data from third party sources.
    
    â”œâ”€â”€ Pipelines               <- folder contains processing and modeling steps designed to automate, standardize and streamline the process of building, training, evaluating and deploying machine learning models
    â”‚
    â”œâ”€â”€ steps             <- folder contains a single piece or stage of a ZenML pipeline
    â”‚
    â”œâ”€â”€ test          <- Jupyter notebooks. 
  
    â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    â”‚                         generated with `pip freeze > requirements.txt`
    â”‚
    â”œâ”€â”€ app.py           <- streamlit app code

--------

 ![image](maintainence.jpg)

# project-Dashboard:
  https://project-6-6dte.onrender.com
# Overview
   The goal is to develop a predictive maintenance model that can predict equipment failures before they occur. The dataset includes sensor readings and maintenance logs from a variety of machines.

# Features
- Data Collection: Gathered Airbnb data from various sources, including MongoDB.
- Data Preprocessing: Cleaned and prepared the data for analysis. 
- ETL (Extract, Transform, Load): Converted data from MongoDB to structured DataFrames.
- Exploratory Data Analysis (EDA): Performed in-depth analysis and visualization of Airbnb data.
- Interactive Streamlit UI: Developed a user-friendly interface for data exploration and presentation.

# Getting Started

1. Clone the repository:
   
         https://github.com/Kobalan/project-6.git

2. Install required packages:
   
        pip install -r requirements.txt

3. Run the Streamlit app:

       streamlit run app.py


# Methods
- Data Collection: Web scraping, API access, database queries.
- Data Preprocessing: Data cleaning, handling missing values, feature engineering.
- ETL Work: MongoDB data extraction, data transformation using Pandas.
- EDA: Visualization with Matplotlib, Seaborn, and Plotly.
- Model Creation: Create a classification model that predicts whether equipment is failure or not failure
- Streamlit UI: Streamlit library for building interactive web applications.

# Skills Covered
- Data collection and integration.
- Data cleaning and preprocessing.
- ETL techniques for data transformation.
- Exploratory Data Analysis (EDA).
- Data visualization.
- Machine Learning
- Web application development with Streamlit.
- Deployment



# Results
- The project provides a user-friendly interface for predicting the equipment is going to failure or not.

**Contact**

ðŸ“§ Email: kobalanm2705@gmail.com 
ðŸŒ LinkedIn: [linkedin.com/in/kobalan-m](https://www.linkedin.com/in/kobalan-m-106267227/)

